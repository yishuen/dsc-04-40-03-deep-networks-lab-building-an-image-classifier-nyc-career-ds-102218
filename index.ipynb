{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Networks - Lab: Building an Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, we'll create a network with more than one hidden layer from scratch. The outline of this lab will be roughly the same as the previous two labs, but you'll notice that adding more hidden layers makes forward and backward propagation more complex. This is what you'll do:\n",
    "\n",
    "- You'll start with initializing the parameters in all the layers.\n",
    "- You'll implement the forward propagation module:\n",
    "     - First, you'll combine a linear step and a activation function in a linear forward function.\n",
    "     - Next, you'll stack the linear forward function L-1 time with a RELU activation function (for layers 1 through L-1) and then add a sigmoid layer at the end (for the final layer $L$). \n",
    "- You'll create the loss function.\n",
    "- You'll mplement the backward propagation module using three helper functions:\n",
    "    - First, you'll create a function for linear part of a layer's backward propagation step.\n",
    "    - Next, we'll tell you how to get the gradients for the activation functions (RELU and sigmoid) and you'll implement this along with the linear part of the activation step to create a backward function.\n",
    "    - Lastly, you'll stack the backward function L-1 times with the RELU activation and add the sigmoid activation in the $L$th layer in a new L_model_backward function\n",
    "- You'll conclude your model with updating the parameters\n",
    "- At the end of this lab, you'll combine all the helper functions in a function called `L_layer_model` and apply this model to the Santa data set you've used before!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Explain the architecture of a neural network\n",
    "* Load and display images from file\n",
    "* Batch load and process directories of images using Keras\n",
    "* Code a multi-layer neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages\n",
    "\n",
    "First, let's import all the packages that you 'll need for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0) \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Initialization in an L-layer Neural Network\n",
    "\n",
    "Let's look at the initialization function you created in the previous lab. We'll try to convert this helper function to a function that can be used in a setting with $L$ layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from the previous lab that, with one hidden layer, we initialized W and b as follows:\n",
    "\n",
    "```python\n",
    "def initialize_parameters(n_0, n_1, n_2):\n",
    "    np.random.seed(123) \n",
    "    W1 = np.random.randn(n_1, n_0) * 0.05 \n",
    "    b1 = np.zeros((n_1, 1))\n",
    "    W2 =  np.random.randn(n_2, n_1) * 0.05 \n",
    "    b2 = np.zeros((n_2, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to generalize this function such that the parameter initialization function takes a list of arbitrary length instead of `(n_0, n_1, n_2)`, and computes as many `W`'s and `b`'s as there are layers, (hence, L of each). In this function, you'll loop over the list which is entered as an argument in `initialize_parameters_deep`. For each layer $l$, initialize $W^{[l]}$ and $b^{[l]}$.\n",
    "\n",
    "To make it a little easier, recall from the lexture that \n",
    "\n",
    "$$W^{[l]}: (n^{[l]}, n^{[l-1]})$$\n",
    "\n",
    "$$b^{[l]}: (n^{[l]}, 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(n_layer):\n",
    "    \n",
    "    np.random.seed(123)\n",
    "    parameters = {}\n",
    "    L = len(n_layer)           \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(n_layer[l], n_layer[l-1])*0.05\n",
    "        parameters['b' + str(l)] = np.zeros((n_layer[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward propagation\n",
    "\n",
    "### 3.1. Linear forward and activation for 1 layer\n",
    "Let's start building on a propagation module. As you know, in each layer of nodes $l$, two things happen\n",
    "\n",
    "- A linear transformation $Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}$, where $A^{[0]} = X$. You may also find `np.dot()` useful here.\n",
    "- An activation function is applied to the linear transformation. in this lab, the two activation functions are used in the neural network are:\n",
    "    - *Sigmoid*: $A^{[l]} = \\sigma(Z^{[l]}) = \\frac{1}{ 1 + e^{-(Z^{[l]})}}$. You can          program this in python using `np.exp()`.\n",
    "    - *ReLU*: The mathematical formula for ReLu is $A^{[l]} $= RELU$(Z^{[l]})$ =$ \\max(0, Z^{[l]})$. You can  program this in python using `np.maximum()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this function will be the activation A. Additionally, we save some intermediate values for our backpropagation later on. Define `1inear_cache` saves the elements of the linear transformation `(A_prev, W, b)`, `activation_cache` save `Z`. They are stored together in one dictionary, `cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the templated function below as indicated by the comments\n",
    "#Be sure to also carefully review the function in general in order to continue building your understanding.\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    " \n",
    "    Z = np.dot(W, A_prev) + b #Your code here; see the linear transformation above for how to compute Z\n",
    "    linear_cache = (A_prev, W, b)\n",
    "    activation_cache = Z\n",
    "    \n",
    "    #Here we define two possible activation functions\n",
    "    if activation == \"sigmoid\":\n",
    "        A = 1/(1+np.exp(-Z)) #Your code here; use the appropriate function for a sigmoid activation function\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        A = np.maximum(0,Z) #Your code here; use the appropriate function for the ReLU activation function.\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Extending to  L layers\n",
    "\n",
    "In this lab, we'll build a neural network with $L-1$ RELU layers and the last layer L with a SIGMOID activation function. Let's build a function that implements this using `linear_activation_forward()`.\n",
    "\n",
    "The second argument of the function `L_model_forward` is `parameters`. Recall that this is a dictionary storing (initialized) parameters `W` and `b` for each layer of the network. We'll loop over all the values of W and b, and they are inputs of the function `linear_activation_forward`. Recall that you can use something like this to loop over `W1`, `W2`, etc.: `parameters['W'+ str(i)]` with `i` the index value.\n",
    "\n",
    "We denote `AL` the output of the last layer (so, $\\hat y$).\n",
    "\n",
    "\n",
    "Make sure to keep track of the caches in the \"caches\" list. To add a new value `cache` to a `list`, you can use `list.append(cache)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once again, complete this templated function as indicated by the comments provided.\n",
    "def L_model_forward(X, parameters):\n",
    "    #Initialize a cache list to keep track of the caches\n",
    "    caches = [] #Your code here\n",
    "    A = X\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    \n",
    "    # Implement the RELU activation L-1 times. Add \"cache\" to the \"caches\" list.\n",
    "    #Your code here\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W'+ str(l)], parameters['b' + str(l)], activation = \"relu\")        \n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement the sigmoid function for the last layer. Add \"cache\" to the \"caches\" list.\n",
    "    #Your code here\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you have a full forward propagation that takes the input X and outputs a row vector $A^{[L]}$ containing your predictions. It also records all intermediate values in \"caches\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The cost function\n",
    "\n",
    "Just like in the last lab, the activation in the last layer provides us with the preditions on all the samples. The activations were denoted as $a^{[2] (i)}$ in the last lab (where we had one hidden layer), here they are \n",
    "$a^{[L] (i)}$, or our vectorized $A^{[L]}$ output from `L_model_forward`. The resulting cross-entropy cost is essentially the same:\n",
    "\n",
    "$$J = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the templated function below, as indicated by the comments.\n",
    "def compute_cost(AL, Y):\n",
    "        \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    cost = -(1/m)* np.sum((Y*np.log(AL))+ (1-Y)*np.log(1-AL)) #Your code here; use the formula above to calculate the cost.\n",
    "    cost = np.squeeze(cost)      # To make sure to get shape right (e.g. turn [[17]] into 17)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Backward propagation\n",
    "\n",
    "Just like with forward propagation, you will implement helper functions for backpropagation. Remember that back propagation is used to calculate the gradient of the loss function with respect to the parameters. \n",
    "\n",
    "$$\\frac{d \\mathcal{L}(a^{[2]},y)}{{dz^{[1]}}} = \\frac{d\\mathcal{L}(a^{[2]},y)}{{da^{[2]}}}\\frac{{da^{[2]}}}{{dz^{[2]}}}\\frac{{dz^{[2]}}}{{da^{[1]}}}\\frac{{da^{[1]}}}{{dz^{[1]}}} \\tag{8} $$\n",
    "\n",
    "$$dz^{[1]}= \\frac{d\\mathcal{L}(a^{[2]},y)}{{da^{[2]}}}\\frac{{da^{[2]}}}{{dz^{[2]}}}\\frac{{dz^{[2]}}}{{da^{[1]}}}\\frac{{da^{[1]}}}{{dz^{[1]}}} $$\n",
    "\n",
    "$$dW^{[1]} =  \\frac{d\\mathcal{L}(a^{[2]},y)}{{da^{[2]}}}\\frac{{da^{[2]}}}{{dz^{[2]}}}\\frac{{dz^{[2]}}}{{da^{[1]}}}\\frac{{da^{[1]}}}{{dz^{[1]}} }\\frac{\\partial z^{[1]} }{\\partial W^{[1]}}$$\n",
    "\n",
    "$$db^{[1]} =  \\frac{d\\mathcal{L}(a^{[2]},y)}{{da^{[2]}}}\\frac{{da^{[2]}}}{{dz^{[2]}}}\\frac{{dz^{[2]}}}{{da^{[1]}}}\\frac{{da^{[1]}}}{{dz^{[1]}} }\\frac{\\partial z^{[1]} }{\\partial b^{[1]}}$$\n",
    "\n",
    "You are going to build the backward propagation in three steps:\n",
    "- First let's build a `linear_backward` function\n",
    "- Then let's build a libear --> activation backward function where the activation computes the derivative of either the ReLU or sigmoid activation\n",
    "- lastly, let's backpropagate through the entire model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Linear backward\n",
    "\n",
    "***CHANGE THIS*** TRY TO DO LINEAR AND NON-LINEAR IN 1 FUNCTION\n",
    "\n",
    "For layer $l$, the linear part is: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (followed by an activation).\n",
    "\n",
    "Suppose you have already calculated the derivative $dZ^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial Z^{[l]}}$. You want to get $(dW^{[l]}, db^{[l]} dA^{[l-1]})$.\n",
    "\n",
    "\n",
    "The three outputs $(dW^{[l]}, db^{[l]}, dA^{[l]})$ are computed using the input $dZ^{[l]}$.Here are the formulas you need:\n",
    "$$ dW^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} \\tag{8}$$\n",
    "$$ db^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}\\tag{9}$$\n",
    "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \\tag{10}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Use the 3 formulas above to implement linear_backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the skeleton function below\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache #Unpacking our complex object\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m) * np.dot(dZ,A_prev.T) #Your code here; see the formulas above\n",
    "    db = (1/m) * np.sum(dZ, axis =1, keepdims = True) #Your code here; see the formulas above\n",
    "    dA_prev = np.dot(W.T , dZ) #Your code here; see the formulas above\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2  Linear and activation backward\n",
    "\n",
    "\n",
    "Next, you will create a function that merges the two helper functions: **`linear_backward`** and the backward step for the activation **`linear_activation_backward`**. \n",
    "\n",
    "To help you implement `linear_activation_backward`, we provided two backward functions:\n",
    "- **`sigmoid_backward`**: Implements the backward propagation for SIGMOID unit. Recall that $ dZ^{[l]}= dA ^{[l]} * g^{[l]'} (Z^{[l]})$, and for sigmoid $g^{[l]'} (Z^{[l]}) = \\dfrac{1}{(1+\\exp(-Z))}\\biggr(1- \\dfrac{1}{(1+\\exp(-Z))}\\biggr) $\n",
    "\n",
    "\n",
    "```python\n",
    "dZ = sigmoid_backward(dA, activation_cache)\n",
    "```\n",
    "\n",
    "- **`relu_backward`**: Implements the backward propagation for RELU unit. You can call it as follows:\n",
    "\n",
    "```python\n",
    "dZ = relu_backward(dA, activation_cache)\n",
    "```\n",
    "\n",
    "If $g(.)$ is the activation function, \n",
    "`sigmoid_backward` and `relu_backward` compute $$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]}) \\tag{11}$$.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the skeleton function below\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    Z= activation_cache\n",
    "    \n",
    "    if activation == \"sigmoid\": \n",
    "        s = 1/(1+np.exp(-Z))  #Your code here; see the formula above\n",
    "        dZ = dA * s * (1-s) #Your code here; see the formula above\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"relu\":\n",
    "        dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "        dZ[Z <= 0] = 0 #Your code here; see the formula above\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - L-Model Backward \n",
    "\n",
    "***CHANGE THIS***\n",
    "\n",
    "Now you will implement the backward function for the whole network. Recall that when you implemented the `L_model_forward` function, at each iteration, you stored a cache which contains (X,W,b, and z). In the back propagation module, you will use those variables to compute the gradients. Therefore, in the `L_model_backward` function, you will iterate through all the hidden layers backward, starting from layer $L$. On each step, you will use the cached values for layer $l$ to backpropagate through layer $l$. Figure 5 below shows the backward pass. \n",
    "\n",
    "** Initializing backpropagation**:\n",
    "To backpropagate through this network, we know that the output is, \n",
    "$A^{[L]} = \\sigma(Z^{[L]})$. Your code thus needs to compute `dAL` $= \\frac{\\partial \\mathcal{L}}{\\partial A^{[L]}}$.\n",
    "To do so, use this formula (derived using calculus which you don't need in-depth knowledge of):\n",
    "```python\n",
    "dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost wrt AL\n",
    "```\n",
    "\n",
    "You can then use this post-activation gradient `dAL` to keep going backward. As seen in Figure 5, you can now feed in `dAL` into the LINEAR->SIGMOID backward function you implemented (which will use the cached values stored by the L_model_forward function). After that, you will have to use a `for` loop to iterate through all the other layers using the LINEAR->RELU backward function. You should store each dA, dW, and db in the grads dictionary. To do so, use this formula : \n",
    "\n",
    "$$grads[\"dW\" + str(l)] = dW^{[l]}\\tag{15} $$\n",
    "\n",
    "For example, for $l=3$ this would store $dW^{[l]}$ in `grads[\"dW3\"]`.\n",
    "\n",
    "**Exercise**: Implement backpropagation for the *[LINEAR->RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID* model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the skeleton function below (there are 3 lines that need to be completed)\n",
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) #Your code here; see the code snippet above\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\") #Your code here; use the helper function defined above\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        # (RELU -> LINEAR) gradients\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, activation = \"relu\") #Your code here; use the helper function defined above\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6  Parameter updates\n",
    "\n",
    "In this section you will update the parameters of the model, using gradient descent: \n",
    "\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} $$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} $$\n",
    "\n",
    "where $\\alpha$ is the learning rate. After computing the updated parameters, store them in the parameters dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `update_parameters()` to update your parameters using gradient descent.\n",
    "\n",
    "**Instructions**:\n",
    "Update parameters using gradient descent on every $W^{[l]}$ and $b^{[l]}$ for $l = 1, 2, ..., L$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    \n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  The data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at how to load a raw image from file and display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PIL\n",
      "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only know how to handle extensions: ['png']; with Pillow installed matplotlib can handle more images",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-87426b07d48a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/validation/santa/00000448.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1359\u001b[0m             raise ValueError('Only know how to handle extensions: %s; '\n\u001b[1;32m   1360\u001b[0m                              \u001b[0;34m'with Pillow installed matplotlib can handle '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m                              'more images' % list(handlers))\n\u001b[0m\u001b[1;32m   1362\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only know how to handle extensions: ['png']; with Pillow installed matplotlib can handle more images"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "filename = 'data/validation/santa/00000448.jpg'\n",
    "img=mpimg.imread(filename)\n",
    "plt.imshow(img)\n",
    "print(img.shape)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  \n",
    "\n",
    "Now let's take a look at how we can \n",
    "\n",
    "Examine the gist of this code, but don't worry if you don't understand all the ins and out of the keras preprocessing method `ImageDataGenerator`. We'll explain in more detail when working with convolutional neural networks. The import piece to note here is the drastic image downgrade that we're doing here. The raw images would contain far more information but this would also be costly in time and hardware resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-51bb83b4b1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_to_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a3957ca83e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get all the data in the directory data/validation (132 images), and reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m test_generator = ImageDataGenerator().flow_from_directory(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtest_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         target_size=(64, 64), batch_size=132) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "# directory path\n",
    "train_data_dir = 'data/train'\n",
    "test_data_dir = 'data/validation'\n",
    "\n",
    "# get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(64, 64), batch_size=132) \n",
    "\n",
    "# get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(64, 64), batch_size=790)\n",
    "\n",
    "# create the data sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the drastic difference of one of these images as compared to the raw file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb1e119f98>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_images[0].shape)\n",
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Normalization\n",
    "\n",
    "Be sure to carefully review the three code blocks below. Here, we demonstrate some common data checks you are apt to perform after importing, followed by standard data normalization to set all values to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples: \" + str(m_test))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images_orig shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training and test examples \n",
    "train_img = train_images.reshape(train_images.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_img = test_images.reshape(test_images.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_img/255.\n",
    "test_x = test_img/255.\n",
    "\n",
    "print (\"train_img's shape: \" + str(train_img.shape))\n",
    "print (\"test_img's shape: \" + str(test_img.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output needs to be of shape $(1, X_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the labels\n",
    "train_labels_final = train_labels.T[[1]]\n",
    "test_labels_final = test_labels.T[[1]]\n",
    "\n",
    "print (\"train_labels_final's shape: \" + str(train_labels_final.shape))\n",
    "print (\"test_labels_final's shape: \" + str(test_labels_final.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [12288, 20, 7, 5, 1] #  4-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review and complete the skeleton function below.\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.005, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    np.random.seed(1)\n",
    "    costs = []                         \n",
    "    \n",
    "    # Parameters initialization. (≈ 1 line of code)\n",
    "    parameters = #Your code here; use the previous helper functions\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = #Your code here; use the previous helper functions\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = #Your code here; use the previous helper functions\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = #Your code here; use the previous helper functions\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = #Your code here; use the previous helper functions\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = #Your code here; use the helper function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No edits needed here; simply review the code below.\n",
    "def predict(X, y, parameters):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2\n",
    "    \n",
    "    # Forward propagation\n",
    "    probs, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    # convert probs to 0/1 predictions\n",
    "    for i in range(0, probs.shape[1]):\n",
    "        if probs[0,i] > 0.50:\n",
    "            probs[0,i] = 1\n",
    "        else:\n",
    "            probs[0,i] = 0\n",
    "    \n",
    "    #print (\"predictions: \" + str(probs)); print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((probs == y)/m)))\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = #Your code here; use the helper function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7045454545454546\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(test_img, test_labels_final, parameters) #Your code here; use the helper function defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Print mislabeled images\n",
    "\n",
    "Finally, here we demonstrate iterating through our images and printing those that are mislabbeled. Be sure to make note of the code used for displaying these images, similar to what we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mislabeled_images(classes, X, y, p):\n",
    "    a = p + y\n",
    "    mislabeled_indices = np.asarray(np.where(a == 1))\n",
    "    plt.rcParams['figure.figsize'] = (90.0, 90.0) # set default size of plots\n",
    "    num_images = len(mislabeled_indices[0])\n",
    "    for i in range(num_images):\n",
    "        index = mislabeled_indices[1][i]\n",
    "        \n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(X[:,index].reshape(64,64,3), interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "      #  plt.title(\"Prediction: \" + list(classes.keys())[list(classes.values()).index(int(p[0,index]))] +\n",
    "       #           \" \\n Class: \" + list(classes.keys())[list(classes.values()).index(int(y[0,index]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 6480x6480 with 39 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_mislabeled_images(list(train_generator.class_indices), test_img, test_labels_final, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, you once again practiced and reviewed the process of building a nueral network. This time, we built a more complex network with additional layers which drastically improves the performance on our data set with Santa images! We also made note of some important methods for importing and displaying images, a necessary preliminary step in building image recognition systems.\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "c4HO0",
   "launcher_item_id": "lSYZM"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
